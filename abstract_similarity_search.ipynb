{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNi8FUxNGmYIVmIgDtDPx7J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pP2D_kcTC-zx"},"outputs":[],"source":["# ✅ 1. 패키지 설치 및 초기 모델 로딩\n","!pip install transformers datasets sentencepiece nltk\n","from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n","\n","model_name = \"google/pegasus-large\"\n","tokenizer = PegasusTokenizer.from_pretrained(model_name)\n","model = PegasusForConditionalGeneration.from_pretrained(model_name)"]},{"cell_type":"code","source":["# ✅ 2. 데이터 로딩\n","!wget https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021/resolve/main/arxiv-abstracts.jsonl.gz\n","import gzip\n","import shutil\n","import json\n","\n","with gzip.open('arxiv-abstracts.jsonl.gz', 'rb') as f_in:\n","    with open('arxiv-abstracts.jsonl', 'wb') as f_out:\n","        shutil.copyfileobj(f_in, f_out)\n","\n","filtered_papers = []\n","\n","with open('arxiv-abstracts.jsonl', 'r') as f:\n","    for line in f:\n","        data = json.loads(line)\n","        categories = data.get('categories', [])\n","        if any('cs.' in category for category in categories):\n","            filtered_papers.append({\n","                \"title\": data[\"title\"].strip(),\n","                \"abstract\": data[\"abstract\"].strip()\n","            })\n","\n","print(f\"총 {len(filtered_papers)}개의 Computer Science 논문이 로드됨.\")\n"],"metadata":{"id":"dbSYyAC4DGVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ✅ 3. 사전학습 데이터 생성\n","from transformers import PegasusTokenizer\n","from tqdm import tqdm\n","import torch\n","import random\n","import os\n","\n","# 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# PEGASUS tokenizer 로드\n","tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n","\n","# 문장 분리 + GSG-style 전처리\n","def simple_sentence_split(text):\n","    sentences = [s.strip() + '.' for s in text.split('.') if len(s.strip()) > 0]\n","    return sentences\n","\n","def gap_sentence_preparation_simple(text, num_sentences_to_mask=3):\n","    sentences = simple_sentence_split(text)\n","    if len(sentences) <= num_sentences_to_mask:\n","        return None\n","    selected = sorted(random.sample(range(len(sentences)), num_sentences_to_mask))\n","    target = \" \".join([sentences[i] for i in selected])\n","    source = \" \".join([sentences[i] for i in range(len(sentences)) if i not in selected])\n","    return source, target\n","\n","# 배치 토크나이징\n","def tokenize_in_batches(text_list, batch_size=128, max_length=512, is_target=False):\n","    all_input_ids = []\n","    all_attention_masks = []\n","\n","    for i in tqdm(range(0, len(text_list), batch_size)):\n","        batch = text_list[i:i+batch_size]\n","        if is_target:\n","            with tokenizer.as_target_tokenizer():\n","                tokenized = tokenizer(batch, truncation=True, padding=\"max_length\",\n","                                      max_length=max_length, return_tensors=\"pt\")\n","        else:\n","            tokenized = tokenizer(batch, truncation=True, padding=\"max_length\",\n","                                  max_length=max_length, return_tensors=\"pt\")\n","\n","        all_input_ids.append(tokenized[\"input_ids\"])\n","        all_attention_masks.append(tokenized[\"attention_mask\"])\n","\n","    return {\n","        \"input_ids\": torch.cat(all_input_ids),\n","        \"attention_mask\": torch.cat(all_attention_masks)\n","    }\n","\n","# 전체 GSG + 토크나이징 + 드라이브 저장까지\n","def process_and_save_chunks(all_papers, chunk_size=10000, output_dir=\"/content/drive/MyDrive/pegasus_datas\"):\n","    os.makedirs(output_dir, exist_ok=True)\n","    chunk_id = 0\n","    train_pairs = []\n","    train_titles = []\n","\n","    for paper in all_papers:\n","        combined_text = paper[\"title\"] + \". \" + paper[\"abstract\"]\n","        result = gap_sentence_preparation_simple(combined_text)\n","        if result:\n","            train_pairs.append(result)\n","            train_titles.append(paper[\"title\"])  # ✅ 같이 저장\n","\n","        if len(train_pairs) == chunk_size:\n","            print(f\"\\n🧩 Chunk {chunk_id+1} - GSG 쌍 {len(train_pairs)}개 처리 중\")\n","\n","            sources = [src for src, _ in train_pairs]\n","            targets = [tgt for _, tgt in train_pairs]\n","\n","            print(\"🔄 Source 토크나이징 중...\")\n","            source_inputs = tokenize_in_batches(sources, max_length=512)\n","\n","            print(\"🔄 Target (labels) 토크나이징 중...\")\n","            target_inputs = tokenize_in_batches(targets, max_length=128, is_target=True)\n","\n","            tokenized_inputs = {\n","                \"input_ids\": source_inputs[\"input_ids\"],\n","                \"attention_mask\": source_inputs[\"attention_mask\"],\n","                \"labels\": target_inputs[\"input_ids\"],\n","                \"titles\": train_titles  # ✅ 진짜 title 추가 저장\n","            }\n","\n","            save_path = os.path.join(output_dir, f\"chunk_{chunk_id:03d}.pt\")\n","            torch.save(tokenized_inputs, save_path)\n","            print(f\"✅ 저장 완료: {save_path}\")\n","\n","            # ✅ 초기화\n","            train_pairs = []\n","            train_titles = []\n","            chunk_id += 1\n","\n","    print(\"\\n🎉 모든 chunk 처리 및 Google Drive 저장 완료!\")\n","\n","\n","\n","process_and_save_chunks(filtered_papers, chunk_size=10000)"],"metadata":{"id":"nWFxBm-XDOH0","executionInfo":{"status":"aborted","timestamp":1748322634405,"user_tz":-540,"elapsed":1,"user":{"displayName":"김동준","userId":"00919442453400366852"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ✅ 4. Pegasus 추가 pretraining\n","import os\n","import torch\n","import gc\n","from transformers import PegasusForConditionalGeneration, Trainer, TrainingArguments\n","from torch.utils.data import Dataset\n","\n","# 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#  Huggingface 로깅 비활성화\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","# GSG Dataset 정의\n","class GSGDataset(Dataset):\n","    def __init__(self, data):\n","        self.input_ids = data[\"input_ids\"]\n","        self.attention_mask = data[\"attention_mask\"]\n","        self.labels = data[\"labels\"]\n","\n","    def __len__(self):\n","        return self.input_ids.size(0)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            \"input_ids\": self.input_ids[idx],\n","            \"attention_mask\": self.attention_mask[idx],\n","            \"labels\": self.labels[idx]\n","        }\n","\n","# A100 기준 학습 인자\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/pegasus_ckpt\",\n","    per_device_train_batch_size=8,          # A100에선 8도 여유로움\n","    gradient_accumulation_steps=4,          # effective batch size = 32\n","    num_train_epochs=1,\n","    logging_steps=10,\n","    save_steps=999999,\n","    save_total_limit=1,\n","    fp16=True,                              # A100에서 fp16 완벽 지원\n","    report_to=\"none\"\n",")\n","\n","# chunk 디렉토리\n","chunk_dir = \"/content/drive/MyDrive/pegasus_chunks\"\n","chunk_files = sorted([f for f in os.listdir(chunk_dir) if f.endswith(\".pt\") and \"part\" not in f])\n","\n","# 0번 ~ 9번 chunk (총 100,000개 샘플) 학습\n","for chunk_id, chunk_file in enumerate(chunk_files[:10]):\n","    print(f\"\\n🚀 [Chunk {chunk_id+1}/10] 학습 시작: {chunk_file}\")\n","\n","    # 불러오기\n","    chunk_path = os.path.join(chunk_dir, chunk_file)\n","    data = torch.load(chunk_path)\n","    dataset = GSGDataset(data)\n","\n","    # 모델\n","    model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\")\n","    trainer = Trainer(model=model, args=training_args, train_dataset=dataset)\n","\n","    # 학습\n","    trainer.train()\n","\n","    # 저장\n","    model_path = f\"/content/drive/MyDrive/pegasus_ckpt/{chunk_file.replace('.pt', '')}\"\n","    model.save_pretrained(model_path)\n","    print(f\"✅ 모델 저장 완료: {model_path}\")\n","\n","    # 정리\n","    del data\n","    del dataset\n","    del model\n","    del trainer\n","    gc.collect()"],"metadata":{"id":"wgU7foMUDRli"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ✅ 5. Pegasus 요약문 생성\n","import os\n","import json\n","import torch\n","from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n","\n","# 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 모델 로드\n","model_path = \"/content/drive/MyDrive/pegasus_ckpt/chunk_009\"\n","model = PegasusForConditionalGeneration.from_pretrained(model_path, local_files_only=True).cuda()\n","tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n","model.eval()\n","\n","# chunk 경로\n","chunk_dir = \"/content/drive/MyDrive/pegasus_datas\"\n","chunk_files = sorted([\n","    f for f in os.listdir(chunk_dir)\n","    if f.endswith(\".pt\") and \"part\" not in f\n","])[10:20]\n","\n","# 저장 경로\n","os.makedirs(\"/content/drive/MyDrive/pegasus_outputs\", exist_ok=True)\n","output_jsonl = \"/content/drive/MyDrive/pegasus_outputs/title_summary_100k.jsonl\"\n","\n","# 추론 설정\n","batch_size = 32\n","num_beams = 2\n","\n","with open(output_jsonl, \"w\", encoding=\"utf-8\") as f_out:\n","    for chunk_id, chunk_file in enumerate(chunk_files):\n","        print(f\"\\n📦 [Chunk {chunk_id+10}] 요약문 생성 시작: {chunk_file}\")\n","        chunk_path = os.path.join(chunk_dir, chunk_file)\n","        data = torch.load(chunk_path)\n","\n","        input_ids = data[\"input_ids\"].cuda()\n","        attention_mask = data[\"attention_mask\"].cuda()\n","        titles = data[\"titles\"]  # ✅ 진짜 타이틀 사용\n","\n","        for i in range(0, len(input_ids), batch_size):\n","            input_batch = input_ids[i:i+batch_size]\n","            attn_batch = attention_mask[i:i+batch_size]\n","            titles_batch = titles[i:i+batch_size]\n","\n","            with torch.no_grad():\n","                summary_ids = model.generate(\n","                    input_batch,\n","                    attention_mask=attn_batch,\n","                    max_length=128,\n","                    num_beams=num_beams,\n","                    no_repeat_ngram_size=3,   # ✅ 반복 방지\n","                    early_stopping=True\n","                )\n","\n","            summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n","\n","            for title, summary in zip(titles_batch, summaries):\n","                f_out.write(json.dumps({\n","                    \"title\": title,\n","                    \"summary\": summary\n","                }, ensure_ascii=False) + \"\\n\")\n","\n","        print(f\"✅ {chunk_file} 생성 및 저장 완료\")\n"],"metadata":{"id":"raz-9-sHDUVx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ✅ 6. SimCSE 임베딩 벡터 생성 (별도의 추가 학습 없이 사용)\n","import os\n","import json\n","import torch\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModel\n","\n","# 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 모델 로드 (SimCSE base version)\n","model_name = \"princeton-nlp/sup-simcse-bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModel.from_pretrained(model_name).cuda()\n","model.eval()\n","\n","# 요약문 로드\n","input_path = \"/content/drive/MyDrive/pegasus_outputs/title_summary_100k.jsonl\"\n","titles = []\n","summaries = []\n","\n","with open(input_path, \"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        obj = json.loads(line)\n","        titles.append(obj[\"title\"])\n","        summaries.append(obj[\"summary\"])\n","\n","# 임베딩 함수 (batch 단위 처리)\n","def get_embeddings(texts, batch_size=32):\n","    all_embeddings = []\n","\n","    for i in tqdm(range(0, len(texts), batch_size)):\n","        batch = texts[i:i+batch_size]\n","        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(\"cuda\")\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs, return_dict=True)\n","            embeddings = outputs.pooler_output  # [CLS] 임베딩 (SimCSE에서는 이게 기준)\n","            all_embeddings.append(embeddings.cpu())\n","\n","    return torch.cat(all_embeddings, dim=0)  # (N, 768)\n","\n","# 임베딩 생성\n","print(\"🔄 SimCSE 임베딩 생성 중...\")\n","summary_embeddings = get_embeddings(summaries)  # shape: (100000, 768)\n","\n","# 저장\n","save_path = \"/content/drive/MyDrive/pegasus_outputs/simcse_summary_embeddings.pt\"\n","torch.save({\n","    \"titles\": titles,\n","    \"embeddings\": summary_embeddings\n","}, save_path)\n","\n","print(f\"✅ 저장 완료: {save_path} (shape: {summary_embeddings.shape})\")\n"],"metadata":{"id":"NJMqQ_w1DXZN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ✅ 7. 실제 검색할 초록의 요약문 및 임베딩 생성 함수 정의\n","import torch\n","import torch.nn.functional as F\n","from transformers import PegasusTokenizer, PegasusForConditionalGeneration, AutoTokenizer, AutoModel\n","from sklearn.metrics.pairwise import cosine_similarity\n","import json\n","\n","# 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 사전 준비: 드라이브 마운트 & 모델 로드\n","pegasus_path = \"/content/drive/MyDrive/pegasus_ckpt/chunk_009\"\n","simcse_path = \"/content/drive/MyDrive/pegasus_outputs/simcse_summary_embeddings.pt\"\n","\n","# PEGASUS\n","pegasus_tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n","pegasus_model = PegasusForConditionalGeneration.from_pretrained(pegasus_path, local_files_only=True).cuda()\n","pegasus_model.eval()\n","\n","# SimCSE\n","simcse_tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n","simcse_model = AutoModel.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\").cuda()\n","simcse_model.eval()\n","\n","# 저장된 임베딩 불러오기\n","data = torch.load(simcse_path)\n","all_titles = data[\"titles\"]\n","all_embeddings = data[\"embeddings\"]  # (100000, 768), CPU 상에 있음\n","\n","# 함수 1: PEGASUS로 요약\n","def summarize_abstract(abstract):\n","    inputs = pegasus_tokenizer(abstract, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=512).to(\"cuda\")\n","    with torch.no_grad():\n","        summary_ids = pegasus_model.generate(\n","            **inputs,\n","            max_length=128,\n","            num_beams=2,\n","            no_repeat_ngram_size=3,\n","            early_stopping=True\n","        )\n","    return pegasus_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","# 함수 2: SimCSE 임베딩 생성\n","def get_simcse_embedding(text):\n","    inputs = simcse_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(\"cuda\")\n","    with torch.no_grad():\n","        outputs = simcse_model(**inputs)\n","        return outputs.pooler_output[0].cpu()  # (768,)\n","\n","# 함수 3: 유사도 top-k\n","def retrieve_top_k(query_vector, candidate_vectors, candidate_titles, top_k=20):\n","    similarities = F.cosine_similarity(query_vector.unsqueeze(0), candidate_vectors)  # (100000,)\n","    topk_indices = torch.topk(similarities, k=top_k).indices\n","    return [(candidate_titles[i], similarities[i].item()) for i in topk_indices]\n","\n","# 전체 시스템 실행\n","def find_similar_papers(abstract):\n","    print(\"🔄 초록 요약 중...\")\n","    summary = summarize_abstract(abstract)\n","    print(f\"📝 요약문: {summary}\")\n","\n","    print(\"🔄 임베딩 생성 중...\")\n","    query_vec = get_simcse_embedding(summary)\n","\n","    print(\"🔍 유사 논문 검색 중...\")\n","    results = retrieve_top_k(query_vec, all_embeddings, all_titles, top_k=20)\n","\n","    print(\"\\n📚 가장 유사한 논문 Top-20:\")\n","    for i, (title, score) in enumerate(results, 1):\n","        print(f\"{i:2d}. ({score:.4f}) {title}\")\n"],"metadata":{"id":"wpIOYXYcDaX0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ✅ 8. 실제 추론\n","abstract_input = \"\"\"A conflict-free k-coloring of a graph assigns one of k different colors to some of the vertices such that, for every vertex v, there is a color that is assigned to exactly one vertex among v and v's neighbors. Such colorings have applications in wireless networking, robotics, and geometry, and are well-studied in graph theory. Here we study the natural problem of the conflict-free chromatic number chi_CF(G) (the smallest k for which conflict-free k-colorings exist). We provide results both for closed neighborhoods N[v], for which a vertex v is a member of its neighborhood, and for open neighborhoods N(v), for which vertex v is not a member of its neighborhood.\n","For closed neighborhoods, we prove the conflict-free variant of the famous Hadwiger Conjecture: If an arbitrary graph G does not contain K_{k+1} as a minor, then chi_CF(G) <= k. For planar graphs, we obtain a tight worst-case bound: three colors are sometimes necessary and always sufficient. We also give a complete characterization of the computational complexity of conflict-free coloring. Deciding whether chi_CF(G)<= 1 is NP-complete for planar graphs G, but polynomial for outerplanar graphs. Furthermore, deciding whether chi_CF(G)<= 2 is NP-complete for planar graphs G, but always true for outerplanar graphs. For the bicriteria problem of minimizing the number of colored vertices subject to a given bound k on the number of colors, we give a full algorithmic characterization in terms of complexity and approximation for outerplanar and planar graphs.\n","For open neighborhoods, we show that every planar bipartite graph has a conflict-free coloring with at most four colors; on the other hand, we prove that for k in {1,2,3}, it is NP-complete to decide whether a planar bipartite graph has a conflict-free k-coloring. Moreover, we establish that any general} planar graph has a conflict-free coloring with at most eight colors.\"\"\"\n","find_similar_papers(abstract_input)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eH75Dl8aLqpq","executionInfo":{"status":"ok","timestamp":1748458372357,"user_tz":-540,"elapsed":4140,"user":{"displayName":"김동준","userId":"00919442453400366852"}},"outputId":"6be611c4-82db-4b79-91a9-706ec5fe71c1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["🔄 초록 요약 중...\n"]},{"output_type":"stream","name":"stderr","text":["Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"]},{"output_type":"stream","name":"stdout","text":["📝 요약문: We show that chi_CF(G)= 1 is NP-complete for planar graphs G, but polynomial for outerplanar graphs. For closed neighborhoods, we show that every planar bipartite graph has a conflict-free coloring with at most four colors; on the other hand, we prove that for k in 1,2,3, it is NPcomplete to decide whether a planar graph with at least four colors has a k-coloring.\n","🔄 임베딩 생성 중...\n","🔍 유사 논문 검색 중...\n","\n","📚 가장 유사한 논문 Top-20:\n"," 1. (0.9937) Conflict-Free Coloring of Planar Graphs\n"," 2. (0.8451) The Parameterized Complexity of Graph Cyclability\n"," 3. (0.8355) Equitable Colorings of $l$-Corona Products of Cubic Graphs\n"," 4. (0.8297) Colouring graphs with constraints on connectivity\n"," 5. (0.8258) Algorithmic Aspects of Regular Graph Covers\n"," 6. (0.8243) On the complete width and edge clique cover problems\n"," 7. (0.8242) Polyhedral studies of vertex coloring problems: The asymmetric\n","  representatives formulation\n"," 8. (0.8223) A note on $\\mathtt{V}$-free $2$-matchings\n"," 9. (0.8208) Rainbow Colouring of Split Graphs\n","10. (0.8189) The complexity of signed graph and edge-coloured graph homomorphisms\n","11. (0.8166) Homomorphism bounds and edge-colourings of $K_4$-minor-free graphs\n","12. (0.8160) Color-line and Proper Color-line Graphs\n","13. (0.8140) A faster FPT Algorithm and a smaller Kernel for Block Graph Vertex\n","  Deletion\n","14. (0.8103) Results for grundy number of the complement of bipartite graphs\n","15. (0.8094) The Maximum k-Differential Coloring Problem\n","16. (0.8088) Fixing improper colorings of graphs\n","17. (0.8086) Models for the k-metric dimension\n","18. (0.8071) Semi-algebraic colorings of complete graphs\n","19. (0.8068) Hadwiger number of graphs with small chordality\n","20. (0.8059) Vertex Cover Gets Faster and Harder on Low Degree Graphs\n"]}]}]}